---
title: "Estimating transmissibility with population stratification"
author: Thibaut Jombart
date: "`r Sys.Date()`"
params:
  solution: FALSE
output:
  rmdformats::readthedown:
    highlight: kate
    css: "../../css/style.css"
link-citations: no
bibliography: "../../biblio/biblio.bib"
---


```{r settings, echo = FALSE}

# Note: use this to get dynamically the css; sadly not compatible with having an
# anchor (.here) within the practical's folder
# css: !expr here::here('css', 'style.css')

# knitr options
knitr::opts_chunk$set(
  fig.width = 8,
  fig.height = 5,
  collapse = TRUE,
  message = FALSE,
  warning = FALSE
)

```



********************************
# Preambule

## Outline of the report

### Estimating transmissibility from stratified population

This report provides a template for estimating transmissibility (i.e., how fast
a disease spreads) from a stratified population. It performs basic descriptive
analyses, and uses different approaches for estimating transmissibility. The key
steps of the report include:

* importing the data from an external file
* identifying key variables in the data
* producing global and stratified epidemic curves
* estimating the growth rate and doubling time from epidemic curves
* estimating the instantaneous reproduction number from epidemic curvse

### The data

To illustrate the different analyses, we use real data reporting daily numbers
of COVID-19 hospitalisations in England as of the 24 October 2020, broken down
to the hospital and National Health Service (NHS) region level. The data is
available online from the NHS England's
[website](https://www.england.nhs.uk/statistics/statistical-work-areas/covid-19-hospital-activity/).
The dataset analysed here is a simplified version, providing incidence of
hospital admissions by NHS trust, stored in the file
[covid_admissions_uk_2020_10_24.xlsx](https://github.com/epiverse-trace/data_pipelines/raw/main/data/covid_admissions_uk_2020_10_24.xlsx).


### Target audience

The analyses presented here are largely automated, and should be of use to any
outbreak analyst. A basic R literacy will be required to adapt the report to
other datasets, most importantly for identifying the variables to be used for
dates of events and stratification. The data used in this report are daily case
incidence. For raw linelists, alternative commands will be supplied in the
section on building epicurves.



## Packages used in this report

### tidyverse

The [tidyverse](https://www.tidyverse.org/) is a collection of **R** packages
designed for data science. Developed with high standards of coding practices and
software development, these packages form a consistent ecosystem to handle and
visualise data. Here, we use the following packages:

* [*dplyr*](https://dplyr.tidyverse.org/) for handling data, making new
  variables, building summaries, number-crunching
  
* [*tidyr*](https://tidyr.tidyverse.org/) to re-arrange tidy/data

* [*ggplot2*](https://ggplot2.tidyverse.org/) to visualise data

* [*magrittr*](https://magrittr.tidyverse.org/) for the piping operator (`%>%`)


Most of these functionalities are summarised in handy cheatsheets. We provide
links to the most relevant ones below:

* [basics of R](http://github.com/rstudio/cheatsheets/raw/master/base-r.pdf)
  (not tidyverse, but they remain very useful)

* [data transformation using *dplyr*](https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf) 

* [data visualisation using *ggplot2*](https://github.com/rstudio/cheatsheets/raw/master/data-visualization-2.1.pdf) 



### Outbreak analytics packages

We use several packages specific to outbreak analytics, including:

* [*linelist*](https://epiverse-trace.github.io/linelist/) to identify key
  epidemiological variables in the data

* [*incidence2*](https://repidemicsconsortium.org/incidence2) to build and
  handle epidemic curves
  
* [*i2extras*](https://repidemicsconsortium.org/i2extras) for estimating growth
  rates using different GLMs from *incidence2* objects
  
* [*EpiEstim*](https://github.com/mrc-ide/EpiEstim) and
  [*EpiNow2*](https://epiforecasts.io/EpiNow2/) for estimating the instantaneous
  reproduction number

For some of these packages, we recommend using the *github* (development)
versions, which can be installed using:
   
```{r install, eval = FALSE}

## instructions for github packages (latest versions)
remotes::install_github("reconhub/i2extras")

```

### Other packages

Other packages we use include:

* [*pacman*](https://github.com/trinker/pacman) for loading and installing packages

* [*rmarkdown*](https://rmarkdown.rstudio.com/) for automated report generation

* [*rio*](https://cran.r-project.org/web/packages/rio/index.html) to read
  `.xlsx` files in

* [*here*](https://here.r-lib.org/) for locating files

Cheatsheets and other resources:

* the *rmarkdown* [cheatsheet](https://github.com/rstudio/cheatsheets/raw/master/rmarkdown-2.0.pdf)

* the *knitr* [website](https://yihui.org/knitr/) documenting many options used
  in *rmarkdown*'s settings and code chunks





********************************
# Data preparation

## Loading libraries

The following code loads required packages; missing packages will be installed
automatically, but will require a working internet connection for the
installation to be successful.

```{r }

if (!require(pacman)) {
  install.packages("pacman")
  library(pacman)
}
p_load(tidyverse)
p_load(here)
p_load(rio)
p_load(linelist)
p_load(incidence2)
p_load(i2extras)

```

##  Importing the data

The data file is named "*covid_admissions_uk_2020_10_24.xlsx*" and is located in
the *data/* folder. To adapt this report to another dataset, change the name of
the file in the script below:

```{r }

path_to_file <- here::here("data", "covid_admissions_uk_2020_10_24.xlsx")
dat_raw <- path_to_file %>%
  rio::import() %>%
  tibble() %>%
  mutate(date = as.Date(date)) # date-time -> date
dat_raw

```

Once imported into __R__, the dataset called `dat` includes:

* `date`: the date of admission
* `region`: the NHS region
* `org_name`: the full name of the NHS trust
* `org_code`: a short code for the NHS trust
* `n`: number of new, confirmed COVID-19 cases admitted, including inpatients
  who tested positive on that day, and new admissions with a positive test



## Identifying key data

__Note__: this is not used for now, as there is no integration of linelist with
other existing tools.

Here we identify the key data needed in the analyses, including:

* the dates to be used, here, dates of hospital admission
* the strata of the population, here, coarse geographic locations (NHS regions)
* the case counts; this would not be needed if the data was a raw linelist, and
  not already aggregated counts

```{r }

dat <- dat_raw %>%
  make_linelist(date_admission = "date",
                location = "region",
                counts = "n",
                allow_extra = TRUE)
dat

```





********************************
# Descriptive analyses

## Epidemic curves

```{r }

# convert daily incidence into weekly incidence using incidence2
dat_i <- dat_raw %>%
  incidence("date",
            interval = "week",
            counts = "n",
            groups = "region")

# summary
dat_i %>%
  summary()

# plot with regions as colors
dat_i %>%
  plot(fill = region, col_pal = muted, angle = 45, legend = "bottom") +
  labs(title = "Weekly incidence of cases")


dat_i %>%
  facet_plot(angle = 45,
             date_format = "%d %b %y",
             n_breaks = 6, nrow = 7)

```




*****************************
## Growth rates

The new package *i2extras* adds a number of tools for *incidence2* objects,
including the implementation of different GLMs to fit epicurves, and derive
growth rates.

To illustrate these approaches, we first select the data so that:

* we use daily incidences by region
* we keep the last 4 weeks of data
* we exclude the last week of data, as it may be prone to biases due to
  reporting delays

```{r }

last_date <- dat %>%
  pull(date) %>%
  max()
last_date

# version using keep_first and keep_last from i2extras
i_recent <- dat %>%
  incidence2::incidence(date,
                        count = n,
                        groups = region) %>% 
  keep_last(4 * 7) %>%  # keep last 4 weeks of data
  keep_first(3 * 7) # remove last week of data as incomplete

## # 'old' version using 'filter'
## i_recent <- dat %>%
##   incidence2::incidence(date,
##                         count = n,
##                         groups = region) %>% 
##   filter(date_index > (last_date - 28), # keep last 4 weeks of data
##          date_index <= (last_date - 7)) # remove last week of data

i_recent %>%
  summary()

i_recent %>% 
  facet_plot()

```



<br>
<div class="exercise">

**Exercise:** We can now fit models to these data. To do so, try doing the following:

1. load the package *i2extras*; if not installed, follow instructions from the package's 
[website](https://www.repidemicsconsortium.org/i2extras/)

2. use the function `fit_curve()` to fit a negative binomial model to the
   incidence data by region, save the output as a new object `last_trends`, and
   plot it
   
3. feed this output to the function `growth_rate()` to obtain estimates of
   growth rates, doubling times and their confidence intervals, for each region;
   the results should resemble:

</div>
<br>

```{r echo = params$solution}

library(i2extras)

last_trends <- i_recent %>%
  fit_curve(model = "poisson")
# version with negbin model needs more iterations to converge
# fit_curve(model = "negbin", control = glm.control(maxit = 1e3))
last_trends
plot(last_trends)

last_trends %>%
  growth_rate()

```

The code below can be used to visualise the results:

```{r }

last_trends %>%
  growth_rate() %>%
  ggplot(aes(y = region, x = r)) +
  geom_point() +
  geom_errorbar(aes(xmin = r_lower, xmax = r_upper)) +
  geom_vline(xintercept = 0, linetype = 2) +
  theme_bw() +
  labs(title = "Estimates of daily growth rates of COVID-19 in England",
       subtitle = sprintf(
         "based on hospital admissions, %s - %s",
         format(min(get_dates(i_recent)), "%d %B %Y"),
         format(max(get_dates(i_recent)), "%d %B %Y")),
       y = "",
       x = "Daily growth rate")

```


<br>
<div class="exercise">

**Exercise:** repeat the same figure with doubling times. Taken together, what
do these results suggest about the evolution of COVID-19 in the UK over the next
weeks? What would be the doubling time for growth rates (*r*) close to 0? When
would you recommend using doubling times for communicating results on the
evolution of an epidemic?

</div>
<br>


```{r echo = params$solution}

last_trends %>%
  growth_rate %>%
  ggplot(aes(y = region, x = time)) +
  geom_point() +
  geom_errorbar(aes(xmin = time_lower, xmax = time_upper)) +
  theme_bw() +
   labs(title = "Estimates of doubling times of COVID-19 in England",
        subtitle = sprintf(
          "based on hospital admissions, %s - %s",
          format(min(get_dates(i_recent)), "%d %B %Y"),
          format(max(get_dates(i_recent)), "%d %B %Y")),
        y = "",
        x = "Doubling time (days)")

```



```{r echo = FALSE, eval = params$solution, results = "asis"}

cat("**Explanation:**<br><br>")

cat(
  "These results show that all regions display significant growth, and we expect cases to keep growing exponentially in the absence of changes in transmission. Doubling times are fine as all confidence intervals of *r* exclude zero. Otherwise, confidence intervals for doubling times would effectively be exclusion intervals, which are a lot harder to communicate. Doubling times should only be reported when the outbreak is significantly growing.<br>")

```



*************************
*************************
# References
